{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                              Review  Rating\n0  nice hotel expensive parking got good deal sta...       4\n1  ok nothing special charge diamond member hilto...       2\n2  nice rooms not 4* experience hotel monaco seat...       3\n3  unique, great stay, wonderful time hotel monac...       5\n4  great stay great stay, went seahawk game aweso...       5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nice hotel expensive parking got good deal sta...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ok nothing special charge diamond member hilto...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>nice rooms not 4* experience hotel monaco seat...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>unique, great stay, wonderful time hotel monac...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>great stay great stay, went seahawk game aweso...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Rating'].value_counts()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"5    9054\n4    6039\n3    2184\n2    1793\n1    1421\nName: Rating, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.countplot(df.Rating)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7fd8475a8a10>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n                   \"this's\": \"this is\",\n                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n                       \"here's\": \"here is\",\n                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" } ","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = df['Review'].str.lower()\ndataset = dataset.to_list()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(dataset)):\n    dataset[i] = [contraction_mapping[word] if word in contraction_mapping.keys() else word  for word in dataset[i].split(' ')]","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(dataset)):\n    dataset[i] = ' '.join(dataset[i])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\n\nPUNCTUATIONS = string.punctuation\ndataset = [each.translate(str.maketrans('', '', PUNCTUATIONS)) for each in dataset]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nY = le.fit_transform(df.Rating)\nY = Y.reshape(-1,1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train = X\nY_train = Y","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nY_train_one_hot_labels = to_categorical(Y_train)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\n\nmax_words = 1000\nmax_len = 150\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(X_train)\nsequences = tokenizer.texts_to_sequences(X_train)\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import Adam\n\ninputs = Input(name='inputs',shape=[max_len])\nlayer = Embedding(max_words,50,input_length=max_len)(inputs)\nlayer = LSTM(64)(layer)\nlayer = Dense(128, name='FC1')(layer)\nlayer = Dropout(0.1)(layer)\nlayer = Dense(64, name='FC2')(layer)\nlayer = Dropout(0.1)(layer)\nlayer = Dense(5, name='out_layer')(layer)\nlayer = Activation('softmax')(layer)\nmodel = Model(inputs=inputs,outputs=layer)\nmodel.summary()\nmodel.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])","execution_count":30,"outputs":[{"output_type":"stream","text":"Model: \"functional_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninputs (InputLayer)          [(None, 150)]             0         \n_________________________________________________________________\nembedding_3 (Embedding)      (None, 150, 50)           50000     \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 64)                29440     \n_________________________________________________________________\nFC1 (Dense)                  (None, 128)               8320      \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 128)               0         \n_________________________________________________________________\nFC2 (Dense)                  (None, 64)                8256      \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 64)                0         \n_________________________________________________________________\nout_layer (Dense)            (None, 5)                 325       \n_________________________________________________________________\nactivation_9 (Activation)    (None, 5)                 0         \n=================================================================\nTotal params: 96,341\nTrainable params: 96,341\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\n\nmodel.fit(sequences_matrix,Y_train_one_hot_labels,batch_size=128,epochs=15,\n          validation_split=0.2)\n# callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)]","execution_count":31,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n129/129 [==============================] - 19s 144ms/step - loss: 1.1686 - accuracy: 0.4780 - val_loss: 0.9357 - val_accuracy: 0.5804\nEpoch 2/10\n129/129 [==============================] - 18s 137ms/step - loss: 0.9601 - accuracy: 0.5573 - val_loss: 0.9150 - val_accuracy: 0.5889\nEpoch 3/10\n129/129 [==============================] - 19s 147ms/step - loss: 0.8948 - accuracy: 0.6001 - val_loss: 0.8966 - val_accuracy: 0.6158\nEpoch 4/10\n129/129 [==============================] - 19s 150ms/step - loss: 0.8480 - accuracy: 0.6199 - val_loss: 0.9205 - val_accuracy: 0.5723\nEpoch 5/10\n129/129 [==============================] - 19s 144ms/step - loss: 0.8137 - accuracy: 0.6380 - val_loss: 0.8880 - val_accuracy: 0.6216\nEpoch 6/10\n129/129 [==============================] - 19s 145ms/step - loss: 0.7790 - accuracy: 0.6507 - val_loss: 0.9059 - val_accuracy: 0.6148\nEpoch 7/10\n129/129 [==============================] - 20s 156ms/step - loss: 0.7602 - accuracy: 0.6674 - val_loss: 0.8899 - val_accuracy: 0.6167\nEpoch 8/10\n129/129 [==============================] - 19s 145ms/step - loss: 0.7344 - accuracy: 0.6750 - val_loss: 0.9158 - val_accuracy: 0.6133\nEpoch 9/10\n129/129 [==============================] - 19s 149ms/step - loss: 0.7193 - accuracy: 0.6844 - val_loss: 0.9422 - val_accuracy: 0.6065\nEpoch 10/10\n129/129 [==============================] - 19s 150ms/step - loss: 0.6994 - accuracy: 0.6945 - val_loss: 0.9659 - val_accuracy: 0.6162\n","name":"stdout"},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fd82c282bd0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sequences = tokenizer.texts_to_sequences(X_test)\ntest_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accr = model.evaluate(test_sequences_matrix,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}